% Data analyses are usually designed to identify some property of the population from which the data are drawn, 
% generalizing beyond the specific data sample. For this reason, data analyses are often designed in a way that guarantees that they produce a low generalization error.
% That is, they are designed so that the result of a data analysis run on sample 
% data does not differ too much from the result one would achieve by running the analysis over the entire population. 
 
% An adaptive data analysis can be seen as a process composed of multiple queries interrogating some data, where the choice of which query to run next may rely on the results of previous queries. 
% The generalization error of individual query/analysis can be controlled by using an array of well-established statistical techniques.
% However, when queries are arbitrarily composed, the different errors can propagate through the chain of different queries and bring high generalization errors. 
% To address this issue, data analysts are designing several techniques that not only guarantee bounds on the generalization errors of single queries but also guarantee bounds on the generalization error of the composed analyses. 
% The choice of which of these techniques to use, 
% often depends on the chain of queries that an adaptive data analysis can generate.
% Specifically, the total number of queries and the depth of the chain of queries is of great significance 
% to guarantee the generalization error, 
% when the composed data analyses are adaptive. 
% So in order to give a precise guarantee of generalization error
% for the program,
% I am interested in analyzing the depth of the chain of queries in a program, i.e., the program's \emph{adaptivity} property.
 % Gap
 % Unfortunately, this depth which relies on the program(implementation) itself is costly in human efforts, and how to statically obtain this information is not well studied to support data analysts.
% \todo{Intro The Program Analysis On non-functional Property}
Some program properties can be expressed in the form of reachability,
such as
whether the output relies on user input, whether the secret data is leaked in the security analysis area, 
whether some pieces of code are executed, etc.
Reachability can tell us the existence of these properties.
% such as whether the output relies on user input.
% for example whether the secret data is leaked in the security area.
However, it cannot tell us how many times or how long these properties hold for programs.
For example, it can not tell us how much data is leaked, which is also crucial in security. This requires extra analysis
of the program's quantitative property. 
To this end, I'm interested in studying the program's quantitative reachability in this proposal. 
By exploiting the quantitative reachability,
many program properties can be 
studied based on it
% expressed
% in a 
% through quantitative reachability
% For example, in resource cost analysis,
such as the number of function calls,
program execution steps,
lines of executed codes,
the power consumption, memory usage, etc. 
Controlling these quantities can improve program reliability, security, privacy, usability, etc.
 For instance, in security, whether and how the program's output is influenced by the user's input
 can be studied based on the 
 quantitative reachability
 of user-defined input w.r.t. the output of the program.
% the performance in terms of the execution time of two pieces of code for the same task can be used to decide which one to use. 
Providing tight bounds on these quantities is useful to improve software design for different potential applications. In this proposal, I will focus on analyzing several quantitative reachability properties of programs that can be used to improve programs' performance, along different axes.

The first reachability quantitative property
 I focus on is the adaptivity of programs in adaptive data analysis.
 This is intuitively defined as the depth of the chain of dependent queries. 
 In adaptive data analysis, the choice of queries can depend on the results of its previous queries. 
 Hence, there form chains of queries in which every query relies on its previous ones.
 Reasoning about adaptivity is useful in controlling the generalization error of adaptive data analysis, which usually propagates sharply along with the chain. 
 Many researchers have found that the generalization error can be controlled well by choosing the appropriate statistic technique according to the adaptivity. Nevertheless, the adaptivity is not always clear to data analysts when they need it. To solve this dilemma, we propose a program analysis algorithm based on dependency graphs, to provide an upper bound on adaptivity to assist data analysts.
This part mainly developed by first defining the \emph{adaptivity} for 
 the adaptive data analysis
 and then designing
 a program analysis framework for estimating the \emph{adaptivity}.
% Next, based on the implementation and experimental results of my \emph{adaptivity} analysis framework, 
% I propose three significant 
% further features can be improved in this framework.
 % and plan to finish the improvement 
 % before the final defense.
% Then according to the connection between the \emph{adaptivity} and the program's resource cost,
% I propose 
% % I propose extensions of this analysis with improved techniques, 
% % and 
% an accurate full-spectrum program resource cost analysis via
% the generalization of my \emph{adaptivity} analysis framework.
% Then according to the similarities between the \emph{adaptivity} and the program's \emph{non-monotonic} resource cost,
% I present 
 % I propose extensions of this analysis with improved techniques, 
 % and 

% In Resource Cost Analysis Area, the Reachability-Bound is an execution property that has broad
% applications in bounding resources cost by a program or analyzing the program's other run-time behaviors.


% Another execution property which is also significant is the non-monotonic quantitative property.
The second quantitative reachability property that I'm interested in is the program's reachability-bound.
This property is a worst-case bound on the number of times a given control location 
 inside a procedure is visited during the program execution.
This execution property has broad
applications in analyzing other program property beyond quantitative reachability.
For example in the resource cost analysis, this quantitative reachability property
can help to provide a tighter
% improve the precision of the 
bound on the resources consumed by a program such as time, memory,
network traffic, power, etc.
In estimating some quantitative property
% this problem is important in computing a precise analysis result.
in the data analysis area, for example, the \emph{adaptivity}
% For example, in the data analysis area 
in PART I, the reachability-bound on each program control location
% helps
% in 
can improve the precision of the estimated bound on the adaptive data analysis program's \emph{adaptivity}.
In the security analysis area, this reachability-bound helps to improve the accuracy
in estimating the program's information leakage or uncertainty propagation, etc.
% , it can also help to improve the accuracy.
Many works in the program analysis area develop algorithms estimating the program's loop bound or overall complexity.
% None of them solve the reachability-bound problem directly, or path-sensitively.
However, there isn't a general analysis algorithm that solves this problem directly or path-sensitively.
To solve these issues and improve the analysis results on this problem, I propose a new algorithm
aiming to find a precise symbolic worst-case reachability-bound on the program's every control location
% than existing works, 
in part II.
% through static analysis.

% in terms of the inputs to that procedure.
% aims to give the accurate reaching times bound
% for every program location.


% a static analysis framework for 
% \todo
{
 The third challenging quantitative reachability property I'm interested in is the program's {non-monotonic} quantitative property.
 This kind of property includes memory usage in the presence of garbage collection,
number of channel connections established that are later closed,
or resources requested to a virtual host which is released after using them. 
The non-monotonic quantitative property is significantly different from the traditional monotonic quantitative property,
such as the program execution time, energy consumption,
% etc. w.r.t. the physical resources,
or the information leakage, etc. with different measurements in different areas.
% ).
These traditional quantitative properties only accumulate during the program execution. 
However, the non-monotonic quantitative property could also decrease along the computation.
To give a precise estimation on this {non-monotonic} quantity, I propose a program analysis framework in PART III.
This new framework will give
a symbolic bound on the program's non-monotonic quantitative property more accurately and efficiently
than existing works.
}
% analysis via
% the generalization of the \emph{adaptivity} analysis framework.
%
% plan to finish the design and implementation in the thesis.
% In the end, 
% I propose an interesting further work on solving the 
% CFL-Reachability problem by reducing it into my \emph{adaptivity} analysis framework, 
% based on observing the similarities between them.
 % onto general program's resource cost analysis,
 %.