% The abstract page environment sets up everything on the page except the text itself.  The title and other header material are put at the top of the page, and the supervisors are listed at the bottom.  A new page is begun both before and after.  Of course, an abstract may be more than one page itself.  If you need more control over the format of the page, you can use the abstract environment, which puts the word "Abstract" at the beginning and single spaces its text.

% 1.5.1 Purpose in writing the abstract

% The abstract should contain a clear and brief statement of the problem, the procedure(s) and/or method(s) followed, the result(s), and the conclusion(s). The purpose of an abstract is to help a reader decide if they want to consult the complete work. 
% As with the title, the abstract is searchable in many databases, including ProQuest Dissertations & Theses Full Text. Include relevant place names, full personal names, and other proper nouns, which can be very useful keywords for scholars locating resources.

% 1.5.2 Written in English and limited in length

% The abstract must be written in English. A dissertation abstract is limited to 350 words or approximately 2,450 characters. A thesis abstract is limited to 250 words or approximately 1,750 characters.

\begin{abstractpage}
   Data analyses are usually designed to identify some property of the population from which the data are drawn, generalizing beyond the specific data sample. For this reason, data analyses are often designed in a way that guarantees that they produce a low generalization error.
   That is, they are designed so that the result of a data analysis run on a sample data does not differ too much from the result one would achieve by running the analysis over the entire population. 
   
   An adaptive data analysis can be seen as a process composed by multiple queries interrogating some data, where the choice of which query to run next may rely on the results of previous queries. 
   The generalization error of each individual query/analysis can be controlled by using an array of well-established statistical techniques.
   However, when queries are arbitrarily composed, the different errors can propagate through the chain of different queries and bring to high generalization error. 
   To address this issue, data analysts are designing several techniques that not only guarantee bounds on the generalization errors of single queries, but that also guarantee bounds on the generalization error of the composed analyses. 
   The choice of which of these techniques to use, often depends on the chain of queries that an adaptive data analysis can generate.
   %The total number of queries and the depth of the chain of queries are of great significance to guarantee the generalization error, when the composed data analyses are adaptive. 
   % Gap
   % Unfortunately, this depth which relies on the program(implementation) itself is costly in human efforts, and how to statically obtain this information is not well studied to support data analysts.
   
   In this work, we consider adaptive data analyses implemented as while-like programs and we design a program analysis which can help with identifying which technique to use to control their generalization error. 
   More specifically, we formalize the intuitive notion of \emph{adaptivity} as a quantitative property of programs. 
   We do this because the adaptivity level of a data analysis is a key measure to choose the right technique. 
   Based on this definition, we design a program analysis for soundly approximating this quantity.
   The program analysis generates a representation of the data analysis as a weighted dependency graph, where the weight is an upper bound on the number of times each variable can be reached, and uses a path search strategy to guarantee an upper bound on the adaptivity. 
   We implement our program analysis  and show that it can help to analyze the adaptivity of several concrete data analyses with different adaptivity structures.\end{abstractpage}
